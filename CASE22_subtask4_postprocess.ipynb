{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ad3f8ff-7da1-44b7-beee-168308d9146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, codecs\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "315a617e-d37e-4d07-9e94-5d9b74de1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5ed3144-52af-48a6-8aa9-6251f2e79a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (set_seed,\n",
    "                          AutoTokenizer\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa1aeab2-b3ba-4563-929a-d3a972eee0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = 'CASE22_subtask4_xlm-roberta-base'\n",
    "# Get model's tokenizer.\n",
    "print('Loading tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name_or_path, use_fast=True)\n",
    "# default to left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "# Define PAD Token = EOS Token = 50256\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe4732-8afc-4caf-8b98-17ed8e94a520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6c88941e-2ba7-448c-b998-9f4bd06408c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '▁SAM',\n",
       " 'PLE',\n",
       " '_',\n",
       " 'STAR',\n",
       " 'T',\n",
       " '▁Cuando',\n",
       " '▁ya',\n",
       " '▁se',\n",
       " '▁había',\n",
       " '▁apa',\n",
       " 'gado',\n",
       " '▁el',\n",
       " '▁fuego',\n",
       " '▁que',\n",
       " '▁devo',\n",
       " 'ró',\n",
       " '▁la',\n",
       " '▁formación',\n",
       " '▁más',\n",
       " '▁moderna',\n",
       " '▁de',\n",
       " '▁la',\n",
       " '▁ex',\n",
       " '▁línea',\n",
       " '▁Sar',\n",
       " 'miento',\n",
       " '▁',\n",
       " ',',\n",
       " '▁A',\n",
       " 'ní',\n",
       " 'bal',\n",
       " '▁Fernández',\n",
       " '▁en',\n",
       " 'cendi',\n",
       " 'ó',\n",
       " '▁otra',\n",
       " '▁ho',\n",
       " 'guera',\n",
       " '▁que',\n",
       " '▁continúa',\n",
       " '▁prend',\n",
       " 'ida',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁Para',\n",
       " '▁explicar',\n",
       " '▁los',\n",
       " '▁incendi',\n",
       " 'os',\n",
       " '▁en',\n",
       " '▁los',\n",
       " '▁tren',\n",
       " 'es',\n",
       " '▁de',\n",
       " '▁la',\n",
       " '▁empresa',\n",
       " '▁T',\n",
       " 'BA',\n",
       " '▁',\n",
       " ',',\n",
       " '▁el',\n",
       " '▁ministro',\n",
       " '▁de',\n",
       " '▁Seguridad',\n",
       " '▁y',\n",
       " '▁Justicia',\n",
       " '▁lan',\n",
       " 'zó',\n",
       " '▁una',\n",
       " '▁acusa',\n",
       " 'ción',\n",
       " '▁muy',\n",
       " '▁dura',\n",
       " '▁contra',\n",
       " '▁el',\n",
       " '▁Partido',\n",
       " '▁Obr',\n",
       " 'ero',\n",
       " '▁',\n",
       " ',',\n",
       " '▁el',\n",
       " '▁M',\n",
       " 'ST',\n",
       " '▁',\n",
       " ',',\n",
       " '▁Que',\n",
       " 'bra',\n",
       " 'cho',\n",
       " '▁y',\n",
       " '▁Proyecto',\n",
       " '▁Sur',\n",
       " '▁de',\n",
       " '▁Pino',\n",
       " '▁Sola',\n",
       " 'nas',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁La',\n",
       " '▁acusa',\n",
       " 'ción',\n",
       " '▁por',\n",
       " '▁la',\n",
       " '▁presun',\n",
       " 'ta',\n",
       " '▁responsabilidad',\n",
       " '▁en',\n",
       " '▁los',\n",
       " '▁incidente',\n",
       " 's',\n",
       " '▁de',\n",
       " '▁Castel',\n",
       " 'ar',\n",
       " '▁y',\n",
       " '▁Mer',\n",
       " 'lo',\n",
       " '▁promete',\n",
       " '▁seguir',\n",
       " '▁en',\n",
       " '▁la',\n",
       " '▁Justicia',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁También',\n",
       " '▁rat',\n",
       " 'ific',\n",
       " 'ó',\n",
       " '▁que',\n",
       " '▁José',\n",
       " '▁María',\n",
       " '▁Esco',\n",
       " 'bar',\n",
       " '▁',\n",
       " ',',\n",
       " '▁militante',\n",
       " '▁del',\n",
       " '▁PO',\n",
       " '▁',\n",
       " ',',\n",
       " '▁era',\n",
       " '▁quien',\n",
       " '▁“',\n",
       " '▁estaba',\n",
       " '▁al',\n",
       " '▁frente',\n",
       " '▁”',\n",
       " '▁cuando',\n",
       " '▁se',\n",
       " '▁incendi',\n",
       " 'ó',\n",
       " '▁un',\n",
       " '▁tren',\n",
       " '▁en',\n",
       " '▁la',\n",
       " '▁estación',\n",
       " '▁de',\n",
       " '▁Mer',\n",
       " 'lo',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁En',\n",
       " '▁los',\n",
       " '▁incidente',\n",
       " 's',\n",
       " '▁del',\n",
       " '▁jueves',\n",
       " '▁',\n",
       " ',',\n",
       " '▁no',\n",
       " '▁sólo',\n",
       " '▁se',\n",
       " '▁quem',\n",
       " 'aron',\n",
       " '▁siete',\n",
       " '▁vagon',\n",
       " 'es',\n",
       " '▁con',\n",
       " '▁aire',\n",
       " '▁acondicionado',\n",
       " '▁en',\n",
       " '▁Mer',\n",
       " 'lo',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁En',\n",
       " '▁Castel',\n",
       " 'ar',\n",
       " '▁se',\n",
       " '▁intent',\n",
       " 'ó',\n",
       " '▁prender',\n",
       " '▁fuego',\n",
       " '▁a',\n",
       " '▁otro',\n",
       " '▁tren',\n",
       " '▁al',\n",
       " '▁en',\n",
       " 'ce',\n",
       " 'nder',\n",
       " '▁una',\n",
       " '▁fog',\n",
       " 'ata',\n",
       " '▁bajo',\n",
       " '▁la',\n",
       " '▁loco',\n",
       " 'motor',\n",
       " 'a',\n",
       " '▁',\n",
       " ',',\n",
       " '▁pero',\n",
       " '▁el',\n",
       " '▁incendi',\n",
       " 'o',\n",
       " '▁se',\n",
       " '▁evit',\n",
       " 'ó',\n",
       " '▁cuando',\n",
       " '▁apare',\n",
       " 'ció',\n",
       " '▁la',\n",
       " '▁Guardia',\n",
       " '▁de',\n",
       " '▁In',\n",
       " 'fan',\n",
       " 'tería',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁En',\n",
       " '▁la',\n",
       " '▁estación',\n",
       " '▁se',\n",
       " '▁roba',\n",
       " 'ron',\n",
       " '▁las',\n",
       " '▁máquinas',\n",
       " '▁ex',\n",
       " 'pende',\n",
       " 'doras',\n",
       " '▁de',\n",
       " '▁bolet',\n",
       " 'os',\n",
       " '▁y',\n",
       " '▁también',\n",
       " '▁sa',\n",
       " 'que',\n",
       " 'aron',\n",
       " '▁un',\n",
       " '▁kio',\n",
       " 'sco',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁Según',\n",
       " '▁Fernández',\n",
       " '▁',\n",
       " ',',\n",
       " '▁también',\n",
       " '▁hub',\n",
       " 'o',\n",
       " '▁violencia',\n",
       " '▁frente',\n",
       " '▁al',\n",
       " '▁centro',\n",
       " '▁de',\n",
       " '▁operaciones',\n",
       " '▁de',\n",
       " '▁la',\n",
       " '▁ex',\n",
       " '▁línea',\n",
       " '▁Sar',\n",
       " 'miento',\n",
       " '▁',\n",
       " ',',\n",
       " '▁entre',\n",
       " '▁Castel',\n",
       " 'ar',\n",
       " '▁e',\n",
       " '▁Itu',\n",
       " 'zain',\n",
       " 'gó',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁“',\n",
       " '▁Los',\n",
       " '▁pasajeros',\n",
       " '▁bajar',\n",
       " 'on',\n",
       " '▁a',\n",
       " '▁la',\n",
       " '▁vía',\n",
       " '▁y',\n",
       " '▁a',\n",
       " 'gredi',\n",
       " 'eron',\n",
       " '▁a',\n",
       " '▁los',\n",
       " '▁ma',\n",
       " 'quin',\n",
       " 'istas',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁De',\n",
       " 'stro',\n",
       " 'zaro',\n",
       " 'n',\n",
       " '▁dos',\n",
       " '▁auto',\n",
       " 's',\n",
       " '▁',\n",
       " ',',\n",
       " '▁dos',\n",
       " '▁moto',\n",
       " 's',\n",
       " '▁y',\n",
       " '▁dos',\n",
       " '▁bicicleta',\n",
       " 's',\n",
       " '▁”',\n",
       " '▁',\n",
       " ',',\n",
       " '▁dijo',\n",
       " '▁el',\n",
       " '▁ministro',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁Los',\n",
       " '▁primeros',\n",
       " '▁incidente',\n",
       " 's',\n",
       " '▁comenzar',\n",
       " 'on',\n",
       " '▁cuando',\n",
       " '▁una',\n",
       " '▁formación',\n",
       " '▁se',\n",
       " '▁de',\n",
       " 'tuvo',\n",
       " '▁a',\n",
       " '▁las',\n",
       " '▁7',\n",
       " '▁de',\n",
       " '▁la',\n",
       " '▁mañana',\n",
       " '▁en',\n",
       " '▁la',\n",
       " '▁estación',\n",
       " '▁Itu',\n",
       " 'zain',\n",
       " 'gó',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁Según',\n",
       " '▁el',\n",
       " '▁Gobierno',\n",
       " '▁y',\n",
       " '▁la',\n",
       " '▁empresa',\n",
       " '▁T',\n",
       " 'BA',\n",
       " '▁',\n",
       " ',',\n",
       " '▁esos',\n",
       " '▁dos',\n",
       " '▁tren',\n",
       " 'es',\n",
       " '▁sufri',\n",
       " 'eron',\n",
       " '▁un',\n",
       " '▁“',\n",
       " '▁sabo',\n",
       " 'ta',\n",
       " 'je',\n",
       " '▁”',\n",
       " '▁que',\n",
       " '▁impi',\n",
       " 'dió',\n",
       " '▁re',\n",
       " 'anud',\n",
       " 'ar',\n",
       " '▁el',\n",
       " '▁servicio',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁Al',\n",
       " '▁primero',\n",
       " '▁le',\n",
       " '▁habría',\n",
       " 'n',\n",
       " '▁provoca',\n",
       " 'do',\n",
       " '▁un',\n",
       " '▁corto',\n",
       " 'circ',\n",
       " 'u',\n",
       " 'ito',\n",
       " '▁en',\n",
       " '▁los',\n",
       " '▁circuito',\n",
       " 's',\n",
       " '▁electrónico',\n",
       " 's',\n",
       " '▁',\n",
       " ',',\n",
       " '▁al',\n",
       " '▁segundo',\n",
       " '▁le',\n",
       " '▁habría',\n",
       " 'n',\n",
       " '▁ac',\n",
       " 'cionado',\n",
       " '▁el',\n",
       " '▁fren',\n",
       " 'o',\n",
       " '▁de',\n",
       " '▁emergencia',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁“',\n",
       " '▁Hub',\n",
       " 'o',\n",
       " '▁un',\n",
       " '▁sabo',\n",
       " 'ta',\n",
       " 'je',\n",
       " '▁',\n",
       " ',',\n",
       " '▁fue',\n",
       " '▁una',\n",
       " '▁acción',\n",
       " '▁organizada',\n",
       " '▁y',\n",
       " '▁pre',\n",
       " 'medi',\n",
       " 'tada',\n",
       " '▁',\n",
       " '.',\n",
       " '▁[',\n",
       " 'S',\n",
       " 'EP',\n",
       " ']',\n",
       " '▁Y',\n",
       " '▁lo',\n",
       " '▁hizo',\n",
       " '▁alguien',\n",
       " '▁que',\n",
       " '▁sabe',\n",
       " '▁del',\n",
       " '▁tema',\n",
       " '▁”',\n",
       " '▁',\n",
       " ',',\n",
       " '▁había',\n",
       " '▁dicho',\n",
       " '▁Fernández',\n",
       " '▁el',\n",
       " '▁jueves',\n",
       " '▁en',\n",
       " '▁conferencia',\n",
       " '▁de',\n",
       " '▁prensa',\n",
       " '</s>']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(test_data['test'][5]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c6ac8-5e42-4647-9521-8111ef64edf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e11bc7-e343-4407-8f9a-3c3abaffd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CASE22_combined_labels.json','r') as fp:\n",
    "    label_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "858992bf-0a1e-4551-a510-0a5f5fa9752c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'O',\n",
       " '1': 'B-trigger',\n",
       " '2': 'B-target',\n",
       " '3': 'I-target',\n",
       " '4': 'B-place',\n",
       " '5': 'I-place',\n",
       " '6': 'B-etime',\n",
       " '7': 'I-etime',\n",
       " '8': 'B-fname',\n",
       " '9': 'I-fname',\n",
       " '10': 'B-participant',\n",
       " '11': 'I-trigger',\n",
       " '12': 'I-participant',\n",
       " '13': 'B-organizer',\n",
       " '14': 'I-organizer'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict['ids_to_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eed52e5f-5fb7-43dc-8269-4ba536fc8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['portuguese']#['english', 'portuguese','spanish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f6ba1113-0b50-432c-bf97-19b622b90f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding... english\n",
      "decoding... portuguese\n",
      "decoding... spanish\n"
     ]
    }
   ],
   "source": [
    "for lang in langs:\n",
    "    print('decoding... {}'.format(lang))\n",
    "    with codecs.open('CASE22_test_{}_pred (2).yaml'.format(lang),'r', encoding='utf-8') as fp:\n",
    "        data = yaml.load(fp, Loader=yaml.UnsafeLoader)\n",
    "\n",
    "    predictions = np.argmax(data['predictions'], axis=2)\n",
    "    \n",
    "    test_data = load_from_disk('CASE22_hf/test_{}.hf'.format(lang))\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    # true_predictions = [\n",
    "    #     [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    #     for prediction, label in zip(predictions, labels)\n",
    "    # ]\n",
    "\n",
    "    sentences = []\n",
    "    s = []\n",
    "    with open('{}.txt'.format(lang),'r') as fp:\n",
    "        for d in fp:\n",
    "            if d.isspace():\n",
    "                sentences.append(s)\n",
    "                s = []\n",
    "                continue\n",
    "            s.append(d.replace('\\n',''))\n",
    "    sentences.append(s)\n",
    "\n",
    "    with open('xlm-roberta-base-{}-submission.txt'.format(lang),'w') as fp:\n",
    "        for i, sent in enumerate(sentences):\n",
    "            tokenized_ts = tokenizer.convert_ids_to_tokens(test_data['test'][i]['input_ids'])\n",
    "            predi = predictions[i]\n",
    "            predi = predi[-len(tokenized_ts):]\n",
    "            cnt = 0\n",
    "            for s in sent:\n",
    "                while (cnt < len(tokenized_ts)) and not (tokenized_ts[cnt].startswith(tokenized_ts[1][0])):\n",
    "                    cnt += 1\n",
    "                if cnt == 1 and tokenized_ts[cnt] == '▁SAM':\n",
    "                    fp.write(s+'\\t'+label_dict['ids_to_labels']['0']+'\\n')\n",
    "                    cnt += 1\n",
    "                    continue\n",
    "                if cnt < predi.shape[0]:\n",
    "                    # print('data_{}'.format(label_dict['ids_to_labels'][str(predi[cnt])]))\n",
    "                    fp.write(s+'\\t'+label_dict['ids_to_labels'][str(predi[cnt])]+'\\n')\n",
    "                else:\n",
    "                    fp.write(s+'\\t'+label_dict['ids_to_labels']['0']+'\\n')\n",
    "                cnt += 1\n",
    "            if i < len(sentences)-1:\n",
    "                fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233cf59-6125-4ff6-8f8a-10ec2e24381e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0699b2-db0b-40bc-8581-ee378df6844e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58296af6-7724-4aac-a1d3-673d48e3a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
